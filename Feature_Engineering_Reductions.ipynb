{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e8cff-93ab-4607-a792-1ded424fcf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "def save_csv(df, path): Path(path).parent.mkdir(parents=True, exist_ok=True); df.to_csv(path, index=False)\n",
    "def top_loadings(pca, feature_names, pc=0, topk=10): w = pca.components_[pc]; idx = np.argsort(np.abs(w))[::-1][:topk]; return pd.DataFrame({'feature': np.array(feature_names)[idx], 'loading': w[idx]})\n",
    "\n",
    "X = pd.read_csv('x_train.csv')\n",
    "y = pd.read_csv('y_train.csv').squeeze()\n",
    "X_test = pd.read_csv('x_test.csv')\n",
    "if 'date' in X.columns: X = X.sort_values('date'); y = y.loc[X.index]; X_test = X_test.sort_values('date')\n",
    "split_idx = int(len(X)*0.8)\n",
    "X_train, X_valid = X.iloc[:split_idx].reset_index(drop=True), X.iloc[split_idx:].reset_index(drop=True)\n",
    "y_train, y_valid = y.iloc[:split_idx].reset_index(drop=True), y.iloc[split_idx:].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dbea2d-315a-423b-ae84-017166b819ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Standardisation\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_valid_std = scaler.transform(X_valid)\n",
    "X_test_std = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29040c10-2d4d-41a4-a96d-c6f6178ae6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PCA -  réduction de dimension par PCA, mesure la variance expliquée, transforme les jeux de données et exporte les résultats interprétables\n",
    "\n",
    "pca = PCA(n_components=0.95, svd_solver='full').fit(X_train_std)\n",
    "evr = pd.DataFrame({'pc': np.arange(1, len(pca.explained_variance_ratio_)+1), 'explained_variance_ratio': pca.explained_variance_ratio_})\n",
    "evr['cumulative'] = evr['explained_variance_ratio'].cumsum()\n",
    "X_train_pca = pca.transform(X_train_std); X_valid_pca = pca.transform(X_valid_std); X_test_pca = pca.transform(X_test_std)\n",
    "save_csv(pd.DataFrame(X_train_pca), 'data/processed/X_train_pca.csv')\n",
    "save_csv(pd.DataFrame(X_valid_pca), 'data/processed/X_valid_pca.csv')\n",
    "save_csv(pd.DataFrame(X_test_pca), 'data/processed/X_test_pca.csv')\n",
    "save_csv(evr, 'reports/pca_explained_variance.csv')\n",
    "tl = pd.concat([top_loadings(pca, X.columns, pc=i, topk=10).assign(pc=i+1) for i in range(min(3, pca.n_components_))], ignore_index=True)\n",
    "save_csv(tl, 'reports/pca_top_loadings_pc1_3.csv')\n",
    "print(f'PCA n_components_={pca.n_components_}, variance cumulée≈{evr.cumulative.iloc[-1]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b08ba1-9a83-44b4-b92a-d50162a23b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sélection L1 - réduction par sélection de variables via pénalisation L1, puis exporte les features retenues et les matrices réduites\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "base_clf = LogisticRegression(penalty='l1', solver='saga', max_iter=5000, n_jobs=-1)\n",
    "grid = {'C': np.logspace(-3, 2, 10)}\n",
    "g = GridSearchCV(base_clf, grid, scoring='accuracy', cv=tscv, n_jobs=-1)\n",
    "g.fit(X_train_std, y_train)\n",
    "clf_l1 = g.best_estimator_.fit(X_train_std, y_train)\n",
    "coef = np.abs(clf_l1.coef_).mean(axis=0)\n",
    "selected = np.where(coef > 1e-8)\n",
    "selected_features = X.columns[selected]\n",
    "save_csv(pd.DataFrame({'feature': selected_features}), 'reports/feature_list_l1.csv')\n",
    "save_csv(pd.DataFrame(X_train_std[:, selected], columns=selected_features), 'data/processed/X_train_l1.csv')\n",
    "save_csv(pd.DataFrame(X_valid_std[:, selected], columns=selected_features), 'data/processed/X_valid_l1.csv')\n",
    "save_csv(pd.DataFrame(X_test_std[:, selected], columns=selected_features), 'data/processed/X_test_l1.csv')\n",
    "print(f'L1 a retenu {len(selected_features)} features.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f255a-061b-45f4-b216-aa5d51123e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLS (option) - met en place une troisième réduction de dimension, supervisée, appelée PLS\n",
    "grid_k = {'n_components': list(range(2, 21))}\n",
    "pls = GridSearchCV(PLSRegression(scale=False), grid_k, scoring='neg_mean_squared_error', cv=tscv, n_jobs=-1)\n",
    "pls.fit(X_train_std, y_train) # si la cible est binaire, vous pouvez mapper {0,1} en {-1,1} ou rester en régression + signe\n",
    "pls_best = pls.best_estimator_\n",
    "Z_train = pls_best.transform(X_train_std); Z_valid = pls_best.transform(X_valid_std); Z_test = pls_best.transform(X_test_std)\n",
    "save_csv(pd.DataFrame(Z_train), 'data/processed/X_train_pls.csv')\n",
    "save_csv(pd.DataFrame(Z_valid), 'data/processed/X_valid_pls.csv')\n",
    "save_csv(pd.DataFrame(Z_test), 'data/processed/X_test_pls.csv')\n",
    "print('PLS n_components=', pls_best.n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2701518-19e4-44fc-b371-459f703a91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation rapide - compare rapidement la baseline sans réduction avec les trois réductions (PCA, L1, PLS) à\n",
    "### l’aide d’une régression logistique standard, puis exporte un tableau récapitulatif\n",
    "\n",
    "def eval_setting(Xtr, ytr, Xva, yva, name):\n",
    "text\n",
    "clf = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=5000)\n",
    "text\n",
    "clf.fit(Xtr, ytr); pred = clf.predict(Xva); acc = accuracy_score(yva, pred); return name, acc\n",
    "results = []\n",
    "results.append(eval_setting(X_train_std, y_train, X_valid_std, y_valid, 'Baseline-Std'))\n",
    "results.append(eval_setting(X_train_pca, y_train, X_valid_pca, y_valid, 'PCA'))\n",
    "if 'selected_features' in locals(): results.append(eval_setting(pd.DataFrame(X_train_std)[:, selected], y_train, pd.DataFrame(X_valid_std)[:, selected], y_valid, 'L1'))\n",
    "if 'Z_train' in locals(): results.append(eval_setting(Z_train, y_train, Z_valid, y_valid, 'PLS'))\n",
    "res = pd.DataFrame(results, columns=['setting','accuracy'])\n",
    "save_csv(res, 'reports/results_cv_valid.csv'); res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
